#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CAVååŒæ„ŸçŸ¥å¹¿æ’­ä¼˜åŒ–DQNä¸»ç¨‹åº
æ•´åˆæ•°æ®åŠ è½½ã€ç¯å¢ƒåˆ›å»ºã€æ™ºèƒ½ä½“è®­ç»ƒå’Œç»“æœåˆ†æ
"""

import os
import sys
import json
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from data_loader import MATLABDataLoader
from cav_broadcast_env import CAVBroadcastEnv
from dqn_agent import MaskedDQNAgent
from dqn_trainer import DQNTrainer, create_optimized_config


def setup_matplotlib():
    """è®¾ç½®matplotlibä¸­æ–‡æ˜¾ç¤º"""
    plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False


def load_and_validate_data(file_path):
    """åŠ è½½å¹¶éªŒè¯æ•°æ®"""
    print("=" * 60)
    print("æ­¥éª¤1: æ•°æ®åŠ è½½ä¸éªŒè¯")
    print("=" * 60)

    if not os.path.exists(file_path):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶ {file_path}")
        print("è¯·ç¡®ä¿.matæ–‡ä»¶åœ¨æ­£ç¡®è·¯å¾„ä¸‹")
        return None

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    loader = MATLABDataLoader(file_path)

    # åŠ è½½æ•°æ®
    if loader.load_data():
        print("âœ… æ•°æ®åŠ è½½æˆåŠŸ!")
        loader.print_cav_info()
        return loader
    else:
        print("âŒ æ•°æ®åŠ è½½å¤±è´¥!")
        return None


def create_environment_and_agent(loader, config):
    """åˆ›å»ºç¯å¢ƒå’Œæ™ºèƒ½ä½“"""
    print("\n" + "=" * 60)
    print("æ­¥éª¤2: ç¯å¢ƒä¸æ™ºèƒ½ä½“åˆ›å»º")
    print("=" * 60)

    # åˆ›å»ºç¯å¢ƒï¼ŒåŒ…å« w3 å‚æ•°
    env = CAVBroadcastEnv(
        data_loader=loader,
        w1=config['environment']['w1'],
        w2=config['environment']['w2'],
        w3=config['environment']['w3'],
        sharing_threshold=config['environment']['sharing_threshold'],
        max_distance=config['environment']['max_distance']
    )

    print(f"âœ… ç¯å¢ƒåˆ›å»ºæˆåŠŸ!")
    print(f"   - CAVæ•°é‡: {env.num_cavs}")
    print(f"   - æœ€å¤§ç›®æ ‡æ•°/CAV: {env.max_targets_per_cav}")
    print(f"   - å…±äº«ç‡é˜ˆå€¼: {env.sharing_threshold}")
    print(f"   - æƒé‡ w1={env.w1}, w2={env.w2}, w3={env.w3}")

    # è·å–çŠ¶æ€å’ŒåŠ¨ä½œç©ºé—´ç»´åº¦
    state_dim = env.observation_space.shape[0]
    action_dim = env.action_space.n if hasattr(env.action_space, 'n') else env.max_targets_per_cav

    print(f"   - çŠ¶æ€ç©ºé—´ç»´åº¦: {state_dim}")
    print(f"   - åŠ¨ä½œç©ºé—´ç»´åº¦: {action_dim}")

    # åˆ›å»ºæ™ºèƒ½ä½“ï¼Œä½¿ç”¨ MaskedDQNAgent
    agent = MaskedDQNAgent(
        state_dim=state_dim,
        action_dim=action_dim,
        lr=config['agent']['lr'],
        gamma=config['agent']['gamma'],
        epsilon_start=config['agent']['epsilon_start'],
        epsilon_end=config['agent']['epsilon_end'],
        epsilon_decay=config['agent']['epsilon_decay'],
        buffer_size=config['agent']['buffer_size'],
        batch_size=config['agent']['batch_size'],
        target_update=config['agent']['target_update']
    )

    print(f"âœ… DQNæ™ºèƒ½ä½“åˆ›å»ºæˆåŠŸ!")
    print(f"   - å­¦ä¹ ç‡: {config['agent']['lr']}")
    print(f"   - ç¼“å†²åŒºå¤§å°: {config['agent']['buffer_size']}")

    return env, agent


def train_model(env, agent, config, save_dir):
    """è®­ç»ƒæ¨¡å‹"""
    print("\n" + "=" * 60)
    print("æ­¥éª¤3: DQNæ¨¡å‹è®­ç»ƒ")
    print("=" * 60)

    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = DQNTrainer(env, agent, save_dir=save_dir)

    # å¼€å§‹è®­ç»ƒ
    episode_rewards, objective_values = trainer.train(
        max_episodes=config['training']['max_episodes'],
        eval_frequency=config['training']['eval_frequency'],
        save_frequency=config['training']['save_frequency'],
        early_stopping=config['training']['early_stopping'],
        patience=config['training']['patience']
    )

    print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ!")

    return trainer


def analyze_results(trainer, save_dir):
    """åˆ†æè®­ç»ƒç»“æœ"""
    print("\n" + "=" * 60)
    print("æ­¥éª¤4: ç»“æœåˆ†æ")
    print("=" * 60)

    # ç»˜åˆ¶è®­ç»ƒè¿›åº¦
    trainer.plot_training_progress(save_plots=True)

    # æµ‹è¯•æœ€ç»ˆç­–ç•¥
    test_results, stats = trainer.test_policy(num_episodes=100, verbose=True)

    # ç”Ÿæˆåˆ†ææŠ¥å‘Š
    generate_analysis_report(trainer, test_results, stats, save_dir)

    return test_results, stats


def generate_analysis_report(trainer, test_results, stats, save_dir):
    """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
    report = {
        'training_summary': {
            'total_episodes': len(trainer.episode_rewards),
            'best_episode': trainer.best_episode + 1,
            'best_objective_value': trainer.best_objective_value,
            'final_epsilon': trainer.agent.epsilon,
            'convergence_achieved': len(trainer.objective_values) >= trainer.convergence_window
        },
        'test_performance': {
            'success_rate': np.mean(test_results['meets_threshold']),
            'average_sharing_rate': stats['sharing_rates']['mean'],
            'average_broadcast_count': stats['broadcast_counts']['mean'],
            'average_objective_value': stats['objective_values']['mean'],
            'objective_std': stats['objective_values']['std']
        },
        'optimization_analysis': {
            'sharing_threshold_met': stats['sharing_rates']['mean'] >= trainer.env.sharing_threshold,
            'broadcast_efficiency': stats['broadcast_counts']['mean'] / trainer.env.max_targets_per_cav,
            'information_value_per_broadcast': stats['information_values']['mean'] / max(
                stats['broadcast_counts']['mean'], 1)
        }
    }

    # ä¿å­˜æŠ¥å‘Š
    report_path = os.path.join(save_dir, "analysis_report.json")
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)

    # æ‰“å°å…³é”®ç»“æœ
    print("\nğŸ“Š å…³é”®æ€§èƒ½æŒ‡æ ‡:")
    print(f"   - å…±äº«ç‡é˜ˆå€¼æ»¡è¶³ç‡: {report['test_performance']['success_rate']:.1%}")
    print(f"   - å¹³å‡å…±äº«ç‡: {report['test_performance']['average_sharing_rate']:.3f}")
    print(f"   - å¹³å‡å¹¿æ’­æ•°: {report['test_performance']['average_broadcast_count']:.1f}")
    print(f"   - å¹³å‡ç›®æ ‡å‡½æ•°å€¼: {report['test_performance']['average_objective_value']:.3f}")
    print(f"   - å¹¿æ’­æ•ˆç‡: {report['optimization_analysis']['broadcast_efficiency']:.1%}")

    print(f"\nğŸ“‹ åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")


def save_config(config, save_dir):
    """ä¿å­˜é…ç½®æ–‡ä»¶"""
    config_path = os.path.join(save_dir, "training_config.json")
    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    print(f"ğŸ“ é…ç½®æ–‡ä»¶å·²ä¿å­˜åˆ°: {config_path}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš— CAVååŒæ„ŸçŸ¥å¹¿æ’­ä¼˜åŒ–DQNç³»ç»Ÿ")
    print("=" * 60)

    # è®¾ç½®matplotlib
    setup_matplotlib()

    # é…ç½®å‚æ•°
    config = create_optimized_config()

    # æ–‡ä»¶è·¯å¾„ - è¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹
    data_file_path = "vehicles_density50_penetration0.5.mat"

    # åˆ›å»ºä¿å­˜ç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    save_dir = f"./results/cav_dqn_{timestamp}"
    os.makedirs(save_dir, exist_ok=True)

    try:
        # æ­¥éª¤1: åŠ è½½æ•°æ®
        loader = load_and_validate_data(data_file_path)
        if loader is None:
            return

        # ä¿å­˜é…ç½®
        save_config(config, save_dir)

        # æ­¥éª¤2: åˆ›å»ºç¯å¢ƒå’Œæ™ºèƒ½ä½“
        env, agent = create_environment_and_agent(loader, config)

        # æ­¥éª¤3: è®­ç»ƒæ¨¡å‹
        trainer = train_model(env, agent, config, save_dir)

        # æ­¥éª¤4: åˆ†æç»“æœ
        test_results, stats = analyze_results(trainer, save_dir)

        print("\n" + "=" * 60)
        print("ğŸ‰ ç³»ç»Ÿè¿è¡Œå®Œæˆ!")
        print(f"ğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {save_dir}")
        print("=" * 60)

        # æä¾›åç»­æ“ä½œå»ºè®®
        print("\nğŸ’¡ åç»­æ“ä½œå»ºè®®:")
        print("1. æŸ¥çœ‹è®­ç»ƒè¿›åº¦å›¾å’Œç»“æœåˆ†æ")
        print("2. è°ƒæ•´è¶…å‚æ•°é‡æ–°è®­ç»ƒ")
        print("3. åœ¨æ–°æ•°æ®é›†ä¸Šæµ‹è¯•æ¨¡å‹æ³›åŒ–æ€§èƒ½")
        print("4. åˆ†æCAVä¸ªä½“å¹¿æ’­ç­–ç•¥")

    except Exception as e:
        print(f"\nâŒ ç³»ç»Ÿè¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return


def quick_test():
    """å¿«é€Ÿæµ‹è¯•(ä½¿ç”¨è¾ƒå°‘çš„è®­ç»ƒè½®æ•°)"""
    print("ğŸ§ª å¿«é€Ÿæµ‹è¯•æ¨¡å¼")

    config = create_optimized_config()
    # å‡å°‘è®­ç»ƒè½®æ•°ç”¨äºæµ‹è¯•
    config['training']['max_episodes'] = 100
    config['training']['eval_frequency'] = 20
    config['training']['save_frequency'] = 50

    # å‡å°‘ç½‘ç»œå¤æ‚åº¦
    config['agent']['hidden_dims'] = [128, 64]
    config['agent']['buffer_size'] = 10000

    print("âš™ï¸  ä½¿ç”¨æµ‹è¯•é…ç½® (å‡å°‘è®­ç»ƒè½®æ•°)")

    # è¿è¡Œä¸»ç¨‹åºé€»è¾‘
    main()


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='CAVå¹¿æ’­ä¼˜åŒ–DQNç³»ç»Ÿ')
    parser.add_argument('--test', action='store_true',
                        help='è¿è¡Œå¿«é€Ÿæµ‹è¯•æ¨¡å¼ (è¾ƒå°‘è®­ç»ƒè½®æ•°)')
    parser.add_argument('--data', type=str,
                        default='vehicles_density50_penetration0.5.mat',
                        help='MATLABæ•°æ®æ–‡ä»¶è·¯å¾„')

    args = parser.parse_args()

    # æ›´æ–°æ•°æ®æ–‡ä»¶è·¯å¾„
    if hasattr(args, 'data') and args.data:
        # è¿™é‡Œå¯ä»¥ä¿®æ”¹å…¨å±€å˜é‡æˆ–ä¼ é€’å‚æ•°
        pass

    if args.test:
        quick_test()
    else:
        main()